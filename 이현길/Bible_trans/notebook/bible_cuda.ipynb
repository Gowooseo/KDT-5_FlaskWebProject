{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "import pymysql.cursors as cursors\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchmetrics.functional.classification import f1_score\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pymysql.connect(\n",
    "    host=\"1.251.203.204\",\n",
    "    port=33065,\n",
    "    user=\"root\",\n",
    "    password=\"kdt5\",\n",
    "    db=\"Team4\",\n",
    "    charset=\"utf8\",\n",
    ")\n",
    "cur = conn.cursor(cursors.DictCursor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "select en.text as en, fr.text as fr\n",
    "from language_en as en\n",
    "inner join language_fr as fr\n",
    "on en.id = fr.id\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(sql)\n",
    "langDF_ori = pd.DataFrame(cur.fetchall())\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&()*+,-./:;<=>?@[\\\\]^_{|}~'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punc = string.punctuation.replace(\"'\", \"\").replace(\"`\", \"\")\n",
    "punc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in the beginning god created the heaven and th...</td>\n",
       "      <td>au commencement, dieu créa les cieux et la terre.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and the earth was without form, and void; and ...</td>\n",
       "      <td>la terre était informe et vide: il y avait des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and god said, let there be light: and there wa...</td>\n",
       "      <td>dieu dit: que la lumière soit! et la lumière fut.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and god saw the light, that it was good: and g...</td>\n",
       "      <td>dieu vit que la lumière était bonne; et dieu s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and god called the light day, and the darkness...</td>\n",
       "      <td>dieu appela la lumière jour, et il appela les ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31097</th>\n",
       "      <td>and the spirit and the bride say, come. and le...</td>\n",
       "      <td>et l`esprit et l`épouse disent: viens. et que ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31098</th>\n",
       "      <td>for i testify unto every man that heareth the ...</td>\n",
       "      <td>je le déclare à quiconque entend les paroles d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31099</th>\n",
       "      <td>and if any man shall take away from the words ...</td>\n",
       "      <td>et si quelqu`un retranche quelque chose des pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31100</th>\n",
       "      <td>he which testifieth these things saith, surely...</td>\n",
       "      <td>celui qui atteste ces choses dit: oui, je vien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31101</th>\n",
       "      <td>the grace of our lord jesus christ be with you...</td>\n",
       "      <td>que la grâce du seigneur jésus soit avec tous!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31102 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      en  \\\n",
       "0      in the beginning god created the heaven and th...   \n",
       "1      and the earth was without form, and void; and ...   \n",
       "2      and god said, let there be light: and there wa...   \n",
       "3      and god saw the light, that it was good: and g...   \n",
       "4      and god called the light day, and the darkness...   \n",
       "...                                                  ...   \n",
       "31097  and the spirit and the bride say, come. and le...   \n",
       "31098  for i testify unto every man that heareth the ...   \n",
       "31099  and if any man shall take away from the words ...   \n",
       "31100  he which testifieth these things saith, surely...   \n",
       "31101  the grace of our lord jesus christ be with you...   \n",
       "\n",
       "                                                      fr  \n",
       "0      au commencement, dieu créa les cieux et la terre.  \n",
       "1      la terre était informe et vide: il y avait des...  \n",
       "2      dieu dit: que la lumière soit! et la lumière fut.  \n",
       "3      dieu vit que la lumière était bonne; et dieu s...  \n",
       "4      dieu appela la lumière jour, et il appela les ...  \n",
       "...                                                  ...  \n",
       "31097  et l`esprit et l`épouse disent: viens. et que ...  \n",
       "31098  je le déclare à quiconque entend les paroles d...  \n",
       "31099  et si quelqu`un retranche quelque chose des pa...  \n",
       "31100  celui qui atteste ces choses dit: oui, je vien...  \n",
       "31101     que la grâce du seigneur jésus soit avec tous!  \n",
       "\n",
       "[31102 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# langDF = langDF_ori.replace(f'[{punc}]', '', regex=True).applymap(lambda x: x.lower())\n",
    "langDF = langDF_ori.applymap(lambda x: x.lower())\n",
    "langDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count    31102.000000\n",
       " mean        29.475789\n",
       " std         12.630380\n",
       " min          3.000000\n",
       " 25%         20.000000\n",
       " 50%         27.000000\n",
       " 75%         37.000000\n",
       " max        103.000000\n",
       " dtype: float64,\n",
       " count    31102.000000\n",
       " mean        27.692013\n",
       " std         11.660609\n",
       " min          3.000000\n",
       " 25%         19.000000\n",
       " 50%         26.000000\n",
       " 75%         35.000000\n",
       " max         96.000000\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_tokens(text_iter, language):\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "    for text in text_iter:\n",
    "        yield token_transform[language](text[language_index[language]])\n",
    "\n",
    "\n",
    "SRC_LANGUAGE = \"en\"\n",
    "TGT_LANGUAGE = \"fr\"\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "special_symbols = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]\n",
    "\n",
    "\n",
    "token_transform = {\n",
    "    SRC_LANGUAGE: get_tokenizer(\"spacy\", language=\"en_core_web_sm\"),\n",
    "    TGT_LANGUAGE: get_tokenizer(\"spacy\", language=\"fr_core_news_sm\"),\n",
    "}\n",
    "\n",
    "train_iter = langDF.values\n",
    "\n",
    "len_en = pd.Series([len(token) for token in generate_tokens(train_iter, SRC_LANGUAGE)])\n",
    "len_fr = pd.Series([len(token) for token in generate_tokens(train_iter, TGT_LANGUAGE)])\n",
    "len_en.describe(), len_fr.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': Vocab(), 'fr': Vocab()}\n",
      "12518\n",
      "24646\n"
     ]
    }
   ],
   "source": [
    "def generate_tokens(text_iter, language):\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "    for text in text_iter:\n",
    "        yield token_transform[language](text[language_index[language]])\n",
    "\n",
    "\n",
    "SRC_LANGUAGE = \"en\"\n",
    "TGT_LANGUAGE = \"fr\"\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "special_symbols = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]\n",
    "\n",
    "\n",
    "token_transform = {\n",
    "    SRC_LANGUAGE: get_tokenizer(\"spacy\", language=\"en_core_web_sm\"),\n",
    "    TGT_LANGUAGE: get_tokenizer(\"spacy\", language=\"fr_core_news_sm\"),\n",
    "}\n",
    "\n",
    "vocab_transform = {}\n",
    "for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    train_iter = langDF.values\n",
    "    vocab_transform[language] = build_vocab_from_iterator(\n",
    "        generate_tokens(train_iter, language),\n",
    "        min_freq=1,\n",
    "        specials=special_symbols,\n",
    "        special_first=True,\n",
    "    )\n",
    "\n",
    "for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    vocab_transform[language].set_default_index(UNK_IDX)\n",
    "\n",
    "print(vocab_transform)\n",
    "print(len(vocab_transform[\"en\"]))\n",
    "print(len(vocab_transform[\"fr\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[: x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TokenEmbedder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        emb_size,\n",
    "        max_len,\n",
    "        nhead,\n",
    "        src_vocab_size,\n",
    "        tgt_vocab_size,\n",
    "        dim_feedforward,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.src_tok_emb = TokenEmbedder(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedder(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(emb_size, max_len, dropout)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=emb_size,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        src,\n",
    "        trg,\n",
    "        src_mask,\n",
    "        tgt_mask,\n",
    "        src_padding_mask,\n",
    "        tgt_padding_mask,\n",
    "        memory_key_padding_mask,\n",
    "    ):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(\n",
    "            src=src_emb,\n",
    "            tgt=tgt_emb,\n",
    "            src_mask=src_mask,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_mask=None,\n",
    "            src_key_padding_mask=src_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_padding_mask,\n",
    "            memory_key_padding_mask=memory_key_padding_mask,\n",
    "        )\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.transformer.encoder(\n",
    "            self.positional_encoding(self.src_tok_emb(src)), src_mask\n",
    "        )\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask):\n",
    "        return self.transformer.decoder(\n",
    "            self.positional_encoding(self.tgt_tok_emb(tgt)), memory, tgt_mask\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\envs\\Torch_NLP\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                                                 Param #\n",
       "===============================================================================================\n",
       "Seq2SeqTransformer                                                     --\n",
       "├─TokenEmbedder: 1-1                                                   --\n",
       "│    └─Embedding: 2-1                                                  3,204,608\n",
       "├─TokenEmbedder: 1-2                                                   --\n",
       "│    └─Embedding: 2-2                                                  6,309,376\n",
       "├─PositionalEncoding: 1-3                                              --\n",
       "│    └─Dropout: 2-3                                                    --\n",
       "├─Transformer: 1-4                                                     --\n",
       "│    └─TransformerEncoder: 2-4                                         --\n",
       "│    │    └─ModuleList: 3-1                                            1,581,312\n",
       "│    │    └─LayerNorm: 3-2                                             512\n",
       "│    └─TransformerDecoder: 2-5                                         --\n",
       "│    │    └─ModuleList: 3-3                                            2,372,352\n",
       "│    │    └─LayerNorm: 3-4                                             512\n",
       "├─Linear: 1-5                                                          6,334,022\n",
       "===============================================================================================\n",
       "Total params: 19,802,694\n",
       "Trainable params: 19,802,694\n",
       "Non-trainable params: 0\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = Seq2SeqTransformer(\n",
    "    num_encoder_layers=3,\n",
    "    num_decoder_layers=3,\n",
    "    emb_size=256,\n",
    "    max_len=128,\n",
    "    nhead=8,\n",
    "    src_vocab_size=len(vocab_transform[SRC_LANGUAGE]),\n",
    "    tgt_vocab_size=len(vocab_transform[TGT_LANGUAGE]),\n",
    "    dim_feedforward=512,\n",
    ").to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "summary(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(source, target): \n",
      "['in the beginning god created the heaven and the earth.'\n",
      " 'au commencement, dieu créa les cieux et la terre.']\n",
      "source_batch: torch.Size([63, 128])\n",
      "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
      "        [  12,    6,    6,  ...,    6,    6,    6],\n",
      "        [   5,    5,   34,  ...,   30, 3120, 3120],\n",
      "        ...,\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1]])\n",
      "target_batch: torch.Size([65, 128])\n",
      "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
      "        [  41,    8,   34,  ...,   55, 3632, 3632],\n",
      "        [ 953,   93,   37,  ...,   10,    4,    4],\n",
      "        ...,\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1]])\n"
     ]
    }
   ],
   "source": [
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "\n",
    "    return func\n",
    "\n",
    "\n",
    "def input_transform(token_ids):\n",
    "    return torch.cat(\n",
    "        (torch.tensor([BOS_IDX]), torch.tensor(token_ids), torch.tensor([EOS_IDX])),\n",
    "    )\n",
    "\n",
    "\n",
    "def collator(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch\n",
    "\n",
    "\n",
    "text_transform = {}\n",
    "for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    text_transform[language] = sequential_transforms(\n",
    "        token_transform[language], vocab_transform[language], input_transform\n",
    "    )\n",
    "\n",
    "data_iter = langDF.values\n",
    "dataloader = DataLoader(data_iter, batch_size=BATCH_SIZE, collate_fn=collator)\n",
    "source_tensor, target_tensor = next(iter(dataloader))\n",
    "\n",
    "print(\"(source, target): \")\n",
    "print(next(iter(data_iter)))\n",
    "\n",
    "print(\"source_batch:\", source_tensor.shape)\n",
    "print(source_tensor)\n",
    "\n",
    "print(\"target_batch:\", target_tensor.shape)\n",
    "print(target_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_mask: torch.Size([63, 63])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "target_mask: torch.Size([64, 64])\n",
      "tensor([[0., -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "        [0., 0., -inf,  ..., -inf, -inf, -inf],\n",
      "        [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., -inf, -inf],\n",
      "        [0., 0., 0.,  ..., 0., 0., -inf],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "src_padding_mask: torch.Size([128, 63])\n",
      "tensor([[0., 0., 0.,  ..., 1., 1., 1.],\n",
      "        [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "        [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "        [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "        [0., 0., 0.,  ..., 1., 1., 1.]], device='cuda:0')\n",
      "tgt_padding_mask: torch.Size([128, 64])\n",
      "tensor([[0., 0., 0.,  ..., 1., 1., 1.],\n",
      "        [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "        [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "        [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "        [0., 0., 0.,  ..., 1., 1., 1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def generate_square_subsequnt_mask(s):\n",
    "    mask = (torch.triu(torch.ones((s, s), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = (\n",
    "        mask.float()\n",
    "        .masked_fill(mask == 0, float(\"-inf\"))\n",
    "        .masked_fill(mask == 1, float(0.0))\n",
    "    )\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=DEVICE).type(torch.float)\n",
    "    tgt_mask = generate_square_subsequnt_mask(tgt_seq_len)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).type(torch.float).transpose(0, 1).to(DEVICE)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).type(torch.float).transpose(0, 1).to(DEVICE)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
    "\n",
    "\n",
    "target_input = target_tensor[:-1, :]\n",
    "target_out = target_tensor[1:, :]\n",
    "\n",
    "source_mask, target_mask, src_padding_mask, tgt_padding_mask = create_mask(\n",
    "    source_tensor, target_input\n",
    ")\n",
    "\n",
    "print(\"source_mask:\", source_mask.shape)\n",
    "print(source_mask)\n",
    "print(\"target_mask:\", target_mask.shape)\n",
    "print(target_mask)\n",
    "print(\"src_padding_mask:\", src_padding_mask.shape)\n",
    "print(src_padding_mask)\n",
    "print(\"tgt_padding_mask:\", tgt_padding_mask.shape)\n",
    "print(tgt_padding_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def run(epochs, epoch, model, optimizer, criterion, is_train, use_pbar=True):\n",
    "    model.train() if is_train else model.eval()\n",
    "    data_iter = langDF.values\n",
    "    dataloader = DataLoader(data_iter, batch_size=BATCH_SIZE, collate_fn=collator)\n",
    "    pbar = tqdm(dataloader, total=len(list(dataloader))) if use_pbar else dataloader\n",
    "    losses = 0\n",
    "    for source_batch, target_batch in pbar:\n",
    "        source_batch = source_batch.to(DEVICE)\n",
    "        target_batch = target_batch.to(DEVICE)\n",
    "\n",
    "        target_input = target_batch[:-1, :]\n",
    "        target_output = target_batch[1:, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(\n",
    "            source_batch, target_input\n",
    "        )\n",
    "\n",
    "        logits = model(\n",
    "            src=source_batch,\n",
    "            trg=target_input,\n",
    "            src_mask=src_mask,\n",
    "            tgt_mask=tgt_mask,\n",
    "            src_padding_mask=src_padding_mask,\n",
    "            tgt_padding_mask=tgt_padding_mask,\n",
    "            memory_key_padding_mask=src_padding_mask,\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(\n",
    "            logits.reshape(-1, logits.shape[-1]), target_output.reshape(-1)\n",
    "        )\n",
    "        if is_train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if use_pbar:\n",
    "                pbar.set_description(\n",
    "                    f\"Epoch: {epoch}/{epochs} | Loss: {loss.item():.6f}\"\n",
    "                )\n",
    "        losses += loss.item()\n",
    "    return losses / len(list(dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\envs\\Torch_NLP\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", patience=10, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "pre_loss = 0.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./bible_transformer_2.pth\", map_location=DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100 | Loss: 0.759424: 100%|██████████| 243/243 [00:17<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 1, Loss: 1.092651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/100 | Loss: 0.771764: 100%|██████████| 243/243 [00:17<00:00, 13.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 2, Loss: 1.095540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3/100 | Loss: 0.739536: 100%|██████████| 243/243 [00:17<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 3, Loss: 1.092330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4/100 | Loss: 0.751559: 100%|██████████| 243/243 [00:17<00:00, 13.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 4, Loss: 1.094929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5/100 | Loss: 0.776842: 100%|██████████| 243/243 [00:17<00:00, 14.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 5, Loss: 1.093614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6/100 | Loss: 0.772304: 100%|██████████| 243/243 [00:17<00:00, 14.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 6, Loss: 1.093775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7/100 | Loss: 0.739290: 100%|██████████| 243/243 [00:17<00:00, 13.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 7, Loss: 1.092509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8/100 | Loss: 0.746977: 100%|██████████| 243/243 [00:17<00:00, 13.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 8, Loss: 1.093866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9/100 | Loss: 0.768247: 100%|██████████| 243/243 [00:17<00:00, 13.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 9, Loss: 1.093025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100 | Loss: 0.725301: 100%|██████████| 243/243 [00:17<00:00, 13.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 10, Loss: 1.093700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 11/100 | Loss: 0.757534: 100%|██████████| 243/243 [00:17<00:00, 13.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 11, Loss: 1.094427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 12/100 | Loss: 0.725791: 100%|██████████| 243/243 [00:17<00:00, 13.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 12, Loss: 1.094275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 13/100 | Loss: 0.735526: 100%|██████████| 243/243 [00:17<00:00, 13.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 13, Loss: 1.092688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 14/100 | Loss: 0.742745: 100%|██████████| 243/243 [00:17<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 14, Loss: 1.094436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15/100 | Loss: 0.737125: 100%|██████████| 243/243 [00:17<00:00, 13.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 15, Loss: 1.094014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 16/100 | Loss: 0.737556: 100%|██████████| 243/243 [00:17<00:00, 13.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 16, Loss: 1.092730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 17/100 | Loss: 0.778163: 100%|██████████| 243/243 [00:17<00:00, 13.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 17, Loss: 1.094272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 18/100 | Loss: 0.770796: 100%|██████████| 243/243 [00:17<00:00, 13.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 18, Loss: 1.095010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 19/100 | Loss: 0.770974: 100%|██████████| 243/243 [00:17<00:00, 13.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 19, Loss: 1.092428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 20/100 | Loss: 0.776879: 100%|██████████| 243/243 [00:17<00:00, 13.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 20, Loss: 1.092879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 21/100 | Loss: 0.776478: 100%|██████████| 243/243 [00:17<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 21, Loss: 1.091841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 22/100 | Loss: 0.779126: 100%|██████████| 243/243 [00:17<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 22, Loss: 1.095628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 23/100 | Loss: 0.754221: 100%|██████████| 243/243 [00:17<00:00, 13.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 23, Loss: 1.094516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 24/100 | Loss: 0.771650: 100%|██████████| 243/243 [00:17<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 24, Loss: 1.095594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 25/100 | Loss: 0.764648: 100%|██████████| 243/243 [00:17<00:00, 13.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 25, Loss: 1.098419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 26/100 | Loss: 0.756957: 100%|██████████| 243/243 [00:17<00:00, 13.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 26, Loss: 1.094395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 27/100 | Loss: 0.756193: 100%|██████████| 243/243 [00:17<00:00, 14.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 27, Loss: 1.095089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 28/100 | Loss: 0.764426: 100%|██████████| 243/243 [00:17<00:00, 14.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 28, Loss: 1.094352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 29/100 | Loss: 0.751617: 100%|██████████| 243/243 [00:17<00:00, 14.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 29, Loss: 1.095262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 30/100 | Loss: 0.743924: 100%|██████████| 243/243 [00:17<00:00, 13.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 30, Loss: 1.095875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 31/100 | Loss: 0.757625: 100%|██████████| 243/243 [00:17<00:00, 13.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 31, Loss: 1.094148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 32/100 | Loss: 0.749216: 100%|██████████| 243/243 [00:17<00:00, 13.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 32, Loss: 1.092120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 33/100 | Loss: 0.749668: 100%|██████████| 243/243 [00:17<00:00, 14.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 33, Loss: 1.095568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 34/100 | Loss: 0.779767: 100%|██████████| 243/243 [00:17<00:00, 14.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 34, Loss: 1.095000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 35/100 | Loss: 0.756358: 100%|██████████| 243/243 [00:17<00:00, 14.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 35, Loss: 1.096172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 36/100 | Loss: 0.746672: 100%|██████████| 243/243 [00:17<00:00, 14.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 36, Loss: 1.091822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 37/100 | Loss: 0.765206: 100%|██████████| 243/243 [00:17<00:00, 14.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 37, Loss: 1.092855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 38/100 | Loss: 0.750943: 100%|██████████| 243/243 [00:17<00:00, 14.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 38, Loss: 1.092581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 39/100 | Loss: 0.733644: 100%|██████████| 243/243 [00:17<00:00, 14.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 39, Loss: 1.095834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 40/100 | Loss: 0.763518: 100%|██████████| 243/243 [00:17<00:00, 14.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 40, Loss: 1.096537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 41/100 | Loss: 0.759879: 100%|██████████| 243/243 [00:17<00:00, 14.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 41, Loss: 1.095107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 42/100 | Loss: 0.765886: 100%|██████████| 243/243 [00:17<00:00, 13.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 42, Loss: 1.095337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 43/100 | Loss: 0.743378: 100%|██████████| 243/243 [00:17<00:00, 14.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 43, Loss: 1.093532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 44/100 | Loss: 0.751269: 100%|██████████| 243/243 [00:17<00:00, 13.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 44, Loss: 1.092544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 45/100 | Loss: 0.759253: 100%|██████████| 243/243 [00:17<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 45, Loss: 1.094458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 46/100 | Loss: 0.711143: 100%|██████████| 243/243 [00:17<00:00, 14.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 46, Loss: 1.094879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 47/100 | Loss: 0.769880: 100%|██████████| 243/243 [00:17<00:00, 14.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 47, Loss: 1.094179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 48/100 | Loss: 0.711432: 100%|██████████| 243/243 [00:17<00:00, 14.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 48, Loss: 1.094292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 49/100 | Loss: 0.755688: 100%|██████████| 243/243 [00:17<00:00, 14.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 49, Loss: 1.091288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 50/100 | Loss: 0.742323: 100%|██████████| 243/243 [00:17<00:00, 14.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 50, Loss: 1.095293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 51/100 | Loss: 0.766973: 100%|██████████| 243/243 [00:17<00:00, 13.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 51, Loss: 1.094187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 52/100 | Loss: 0.756366: 100%|██████████| 243/243 [00:17<00:00, 13.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 52, Loss: 1.096018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 53/100 | Loss: 0.769632: 100%|██████████| 243/243 [00:17<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 53, Loss: 1.095232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 54/100 | Loss: 0.731038: 100%|██████████| 243/243 [00:17<00:00, 14.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 54, Loss: 1.093222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 55/100 | Loss: 0.727475: 100%|██████████| 243/243 [00:17<00:00, 14.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 55, Loss: 1.095613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 56/100 | Loss: 0.777355: 100%|██████████| 243/243 [00:17<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 56, Loss: 1.095869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 57/100 | Loss: 0.752174: 100%|██████████| 243/243 [00:17<00:00, 14.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 57, Loss: 1.093301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 58/100 | Loss: 0.769530: 100%|██████████| 243/243 [00:17<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 58, Loss: 1.095884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 59/100 | Loss: 0.731499: 100%|██████████| 243/243 [00:17<00:00, 14.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 59, Loss: 1.093895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 60/100 | Loss: 0.758084: 100%|██████████| 243/243 [00:17<00:00, 13.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 60, Loss: 1.092528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 61/100 | Loss: 0.750105: 100%|██████████| 243/243 [00:17<00:00, 13.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 61, Loss: 1.093449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 62/100 | Loss: 0.741152: 100%|██████████| 243/243 [00:17<00:00, 14.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 62, Loss: 1.092871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 63/100 | Loss: 0.751635: 100%|██████████| 243/243 [00:16<00:00, 14.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 63, Loss: 1.093700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 64/100 | Loss: 0.756819: 100%|██████████| 243/243 [00:17<00:00, 13.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 64, Loss: 1.095282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 65/100 | Loss: 0.742488: 100%|██████████| 243/243 [00:17<00:00, 14.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 65, Loss: 1.093230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 66/100 | Loss: 0.771223: 100%|██████████| 243/243 [00:17<00:00, 13.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 66, Loss: 1.094680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 67/100 | Loss: 0.740926: 100%|██████████| 243/243 [00:17<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 67, Loss: 1.091400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 68/100 | Loss: 0.735361: 100%|██████████| 243/243 [00:17<00:00, 13.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 68, Loss: 1.094770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 69/100 | Loss: 0.745236: 100%|██████████| 243/243 [00:17<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 69, Loss: 1.093462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 70/100 | Loss: 0.765828: 100%|██████████| 243/243 [00:17<00:00, 14.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 70, Loss: 1.094071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 71/100 | Loss: 0.749301: 100%|██████████| 243/243 [00:17<00:00, 14.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 71, Loss: 1.093125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 72/100 | Loss: 0.733556: 100%|██████████| 243/243 [00:17<00:00, 13.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 72, Loss: 1.094629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 73/100 | Loss: 0.749138: 100%|██████████| 243/243 [00:17<00:00, 14.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 73, Loss: 1.096142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 74/100 | Loss: 0.789112: 100%|██████████| 243/243 [00:17<00:00, 14.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 74, Loss: 1.095367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 75/100 | Loss: 0.746375: 100%|██████████| 243/243 [00:17<00:00, 13.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 75, Loss: 1.094006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 76/100 | Loss: 0.736169: 100%|██████████| 243/243 [00:17<00:00, 13.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 76, Loss: 1.092106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 77/100 | Loss: 0.720487: 100%|██████████| 243/243 [00:17<00:00, 13.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 77, Loss: 1.094729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 78/100 | Loss: 0.777267: 100%|██████████| 243/243 [00:17<00:00, 13.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 78, Loss: 1.093533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 79/100 | Loss: 0.755123: 100%|██████████| 243/243 [00:17<00:00, 13.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 79, Loss: 1.092723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 80/100 | Loss: 0.777088: 100%|██████████| 243/243 [00:17<00:00, 13.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 80, Loss: 1.093150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 81/100 | Loss: 0.765519: 100%|██████████| 243/243 [00:17<00:00, 13.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 81, Loss: 1.094819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 82/100 | Loss: 0.741697: 100%|██████████| 243/243 [00:17<00:00, 13.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 82, Loss: 1.094559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 83/100 | Loss: 0.767922: 100%|██████████| 243/243 [00:17<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 83, Loss: 1.094942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 84/100 | Loss: 0.764911: 100%|██████████| 243/243 [00:17<00:00, 13.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 84, Loss: 1.095152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 85/100 | Loss: 0.719574: 100%|██████████| 243/243 [00:17<00:00, 13.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 85, Loss: 1.092926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 86/100 | Loss: 0.734671: 100%|██████████| 243/243 [00:17<00:00, 13.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 86, Loss: 1.091585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 87/100 | Loss: 0.728610: 100%|██████████| 243/243 [00:17<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 87, Loss: 1.093595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 88/100 | Loss: 0.736244: 100%|██████████| 243/243 [00:17<00:00, 13.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 88, Loss: 1.094459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 89/100 | Loss: 0.749107: 100%|██████████| 243/243 [00:17<00:00, 13.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 89, Loss: 1.093976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 90/100 | Loss: 0.757321: 100%|██████████| 243/243 [00:17<00:00, 13.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 90, Loss: 1.092374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 91/100 | Loss: 0.746743: 100%|██████████| 243/243 [00:17<00:00, 13.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 91, Loss: 1.097543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 92/100 | Loss: 0.748724: 100%|██████████| 243/243 [00:17<00:00, 13.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 92, Loss: 1.093009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 93/100 | Loss: 0.756877: 100%|██████████| 243/243 [00:17<00:00, 13.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 93, Loss: 1.093059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 94/100 | Loss: 0.749906: 100%|██████████| 243/243 [00:17<00:00, 13.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 94, Loss: 1.095466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 95/100 | Loss: 0.745055: 100%|██████████| 243/243 [00:17<00:00, 13.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 95, Loss: 1.093400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 96/100 | Loss: 0.767085: 100%|██████████| 243/243 [00:17<00:00, 13.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 96, Loss: 1.092501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 97/100 | Loss: 0.728344: 100%|██████████| 243/243 [00:17<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 97, Loss: 1.095312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 98/100 | Loss: 0.747208: 100%|██████████| 243/243 [00:17<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 98, Loss: 1.093935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 99/100 | Loss: 0.739760: 100%|██████████| 243/243 [00:17<00:00, 13.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 99, Loss: 1.093706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100/100 | Loss: 0.757154: 100%|██████████| 243/243 [00:17<00:00, 13.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved! --- Epoch: 100, Loss: 1.093701\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    loss = run(EPOCHS, epoch, model, optimizer, criterion, is_train=True, use_pbar=True)\n",
    "    scheduler.step(loss)\n",
    "    torch.save(model, f\"bible_transformer_3.pth\")\n",
    "    torch.save(model.state_dict(), f\"bible_transformer_state_3.pth\")\n",
    "    print(f\"Model Saved! --- Epoch: {epoch}, Loss: {loss:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, source_tensor, source_mask, max_len, start_symbol):\n",
    "    source_tensor = source_tensor.to(DEVICE)\n",
    "    source_mask = source_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(source_tensor, source_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len - 1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        target_mask = generate_square_subsequnt_mask(ys.size(0)).to(DEVICE)\n",
    "        target_mask = target_mask.type(torch.float).to(DEVICE)\n",
    "\n",
    "        out = model.decode(ys, memory, target_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat(\n",
    "            [ys, torch.ones(1, 1).type_as(source_tensor.data).fill_(next_word)], dim=0\n",
    "        )\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "def translate(model, source_sentence):\n",
    "    model.eval()\n",
    "    source_tensor = text_transform[SRC_LANGUAGE](source_sentence.lower()).view(-1, 1)\n",
    "    num_tokens = source_tensor.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.float).to(DEVICE)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model, source_tensor, src_mask, max_len=num_tokens + 10, start_symbol=BOS_IDX\n",
    "    ).flatten()\n",
    "    output = vocab_transform[TGT_LANGUAGE].lookup_tokens(\n",
    "        list(tgt_tokens.cpu().numpy())\n",
    "    )[1:-1]\n",
    "    return \" \".join(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_model = torch.load(\"bible_transformer_2.pth\", map_location=DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "et dieu a choisi créature devant jésus christ notre seigneur , et l`appelle seigneur , dont nous croyons en lui disant\n",
      "et j`entendis du ciel une voix forte voix qui disait : lève - toi , sors promptement de l`arche , pour dieu , et cet homme , pour dieu de dieu , qui soit ressuscité des morts .\n",
      "dieu dit à noé : que ce songe , fils de dieu a fait cela est à tous les cieux ,\n"
     ]
    }
   ],
   "source": [
    "output1 = translate(pre_model, \"In the beginning God created the heaven and the earth.\")\n",
    "output2 = translate(\n",
    "    pre_model,\n",
    "    \"And the earth was without form, and void; and darkness was upon the face of the deep. And the Spirit of God moved upon the face of the waters.\",\n",
    ")\n",
    "output3 = translate(pre_model, \"And God said, Let there be light: and there was light.\")\n",
    "print(output1)\n",
    "print(output2)\n",
    "print(output3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "et dieu a choisi créature devant jésus christ notre seigneur , et l`appelle seigneur , dont nous croyons en lui disant\n",
      "et j`entendis du ciel une voix forte voix qui disait : lève - toi , sors promptement de l`arche , pour dieu , et cet homme , pour dieu de dieu , qui soit ressuscité des morts .\n",
      "dieu dit à noé : que ce songe , fils de dieu a fait cela est à tous les cieux ,\n"
     ]
    }
   ],
   "source": [
    "output1_1 = translate(model, \"In the beginning God created the heaven and the earth.\")\n",
    "output2_1 = translate(\n",
    "    model,\n",
    "    \"And the earth was without form, and void; and darkness was upon the face of the deep. And the Spirit of God moved upon the face of the waters.\",\n",
    ")\n",
    "output3_1 = translate(model, \"And God said, Let there be light: and there was light.\")\n",
    "print(output1_1)\n",
    "print(output2_1)\n",
    "print(output3_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"token_transform.pkl\", \"wb\") as f:\n",
    "    pickle.dump(token_transform, f)\n",
    "with open(\"vocab_transform.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vocab_transform, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_NLP38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
