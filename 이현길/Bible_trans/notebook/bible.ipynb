{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "import pymysql.cursors as cursors\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchmetrics.functional.classification import f1_score\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pymysql.connect(\n",
    "    host=\"1.251.203.204\",\n",
    "    port=33065,\n",
    "    user=\"root\",\n",
    "    password=\"kdt5\",\n",
    "    db=\"Team4\",\n",
    "    charset=\"utf8\",\n",
    ")\n",
    "cur = conn.cursor(cursors.DictCursor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "select en.text as en, fr.text as fr\n",
    "from language_en as en\n",
    "inner join language_fr as fr\n",
    "on en.id = fr.id\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(sql)\n",
    "langDF = pd.DataFrame(cur.fetchall())\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the beginning God created the heaven and th...</td>\n",
       "      <td>Au commencement, Dieu créa les cieux et la terre.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And the earth was without form, and void; and ...</td>\n",
       "      <td>La terre était informe et vide: il y avait des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And God said, Let there be light: and there wa...</td>\n",
       "      <td>Dieu dit: Que la lumière soit! Et la lumière fut.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And God saw the light, that it was good: and G...</td>\n",
       "      <td>Dieu vit que la lumière était bonne; et Dieu s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And God called the light Day, and the darkness...</td>\n",
       "      <td>Dieu appela la lumière jour, et il appela les ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31097</th>\n",
       "      <td>And the Spirit and the bride say, Come. And le...</td>\n",
       "      <td>Et l`Esprit et l`épouse disent: Viens. Et que ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31098</th>\n",
       "      <td>For I testify unto every man that heareth the ...</td>\n",
       "      <td>Je le déclare à quiconque entend les paroles d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31099</th>\n",
       "      <td>And if any man shall take away from the words ...</td>\n",
       "      <td>et si quelqu`un retranche quelque chose des pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31100</th>\n",
       "      <td>He which testifieth these things saith, Surely...</td>\n",
       "      <td>Celui qui atteste ces choses dit: Oui, je vien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31101</th>\n",
       "      <td>The grace of our Lord Jesus Christ be with you...</td>\n",
       "      <td>Que la grâce du Seigneur Jésus soit avec tous!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31102 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      en  \\\n",
       "0      In the beginning God created the heaven and th...   \n",
       "1      And the earth was without form, and void; and ...   \n",
       "2      And God said, Let there be light: and there wa...   \n",
       "3      And God saw the light, that it was good: and G...   \n",
       "4      And God called the light Day, and the darkness...   \n",
       "...                                                  ...   \n",
       "31097  And the Spirit and the bride say, Come. And le...   \n",
       "31098  For I testify unto every man that heareth the ...   \n",
       "31099  And if any man shall take away from the words ...   \n",
       "31100  He which testifieth these things saith, Surely...   \n",
       "31101  The grace of our Lord Jesus Christ be with you...   \n",
       "\n",
       "                                                      fr  \n",
       "0      Au commencement, Dieu créa les cieux et la terre.  \n",
       "1      La terre était informe et vide: il y avait des...  \n",
       "2      Dieu dit: Que la lumière soit! Et la lumière fut.  \n",
       "3      Dieu vit que la lumière était bonne; et Dieu s...  \n",
       "4      Dieu appela la lumière jour, et il appela les ...  \n",
       "...                                                  ...  \n",
       "31097  Et l`Esprit et l`épouse disent: Viens. Et que ...  \n",
       "31098  Je le déclare à quiconque entend les paroles d...  \n",
       "31099  et si quelqu`un retranche quelque chose des pa...  \n",
       "31100  Celui qui atteste ces choses dit: Oui, je vien...  \n",
       "31101     Que la grâce du Seigneur Jésus soit avec tous!  \n",
       "\n",
       "[31102 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count    31102.000000\n",
       " mean        29.475789\n",
       " std         12.630380\n",
       " min          3.000000\n",
       " 25%         20.000000\n",
       " 50%         27.000000\n",
       " 75%         37.000000\n",
       " max        103.000000\n",
       " dtype: float64,\n",
       " count    31102.000000\n",
       " mean        27.696515\n",
       " std         11.662017\n",
       " min          3.000000\n",
       " 25%         19.000000\n",
       " 50%         26.000000\n",
       " 75%         35.000000\n",
       " max         96.000000\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_tokens(text_iter, language):\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "    for text in text_iter:\n",
    "        yield token_transform[language](text[language_index[language]])\n",
    "\n",
    "\n",
    "SRC_LANGUAGE = \"en\"\n",
    "TGT_LANGUAGE = \"fr\"\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "special_symbols = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]\n",
    "\n",
    "\n",
    "token_transform = {\n",
    "    SRC_LANGUAGE: get_tokenizer(\"spacy\", language=\"en_core_web_sm\"),\n",
    "    TGT_LANGUAGE: get_tokenizer(\"spacy\", language=\"fr_core_news_sm\"),\n",
    "}\n",
    "\n",
    "train_iter = langDF.values\n",
    "\n",
    "len_en = pd.Series([len(token) for token in generate_tokens(train_iter, SRC_LANGUAGE)])\n",
    "len_fr = pd.Series([len(token) for token in generate_tokens(train_iter, TGT_LANGUAGE)])\n",
    "len_en.describe(), len_fr.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': Vocab(), 'fr': Vocab()}\n"
     ]
    }
   ],
   "source": [
    "def generate_tokens(text_iter, language):\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "    for text in text_iter:\n",
    "        yield token_transform[language](text[language_index[language]])\n",
    "\n",
    "\n",
    "SRC_LANGUAGE = \"en\"\n",
    "TGT_LANGUAGE = \"fr\"\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "special_symbols = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]\n",
    "\n",
    "\n",
    "token_transform = {\n",
    "    SRC_LANGUAGE: get_tokenizer(\"spacy\", language=\"en_core_web_sm\"),\n",
    "    TGT_LANGUAGE: get_tokenizer(\"spacy\", language=\"fr_core_news_sm\"),\n",
    "}\n",
    "\n",
    "vocab_transform = {}\n",
    "for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    train_iter = langDF.values\n",
    "    vocab_transform[language] = build_vocab_from_iterator(\n",
    "        generate_tokens(train_iter, language),\n",
    "        min_freq=1,\n",
    "        specials=special_symbols,\n",
    "        special_first=True,\n",
    "    )\n",
    "\n",
    "for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    vocab_transform[language].set_default_index(UNK_IDX)\n",
    "\n",
    "print(vocab_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[: x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TokenEmbedder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        emb_size,\n",
    "        max_len,\n",
    "        nhead,\n",
    "        src_vocab_size,\n",
    "        tgt_vocab_size,\n",
    "        dim_feedforward,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.src_tok_emb = TokenEmbedder(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedder(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(emb_size, max_len, dropout)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=emb_size,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        src,\n",
    "        trg,\n",
    "        src_mask,\n",
    "        tgt_mask,\n",
    "        src_padding_mask,\n",
    "        tgt_padding_mask,\n",
    "        memory_key_padding_mask,\n",
    "    ):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(\n",
    "            src=src_emb,\n",
    "            tgt=tgt_emb,\n",
    "            src_mask=src_mask,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_mask=None,\n",
    "            src_key_padding_mask=src_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_padding_mask,\n",
    "            memory_key_padding_mask=memory_key_padding_mask,\n",
    "        )\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.transformer.encoder(\n",
    "            self.positional_encoding(self.src_tok_emb(src)), src_mask\n",
    "        )\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask):\n",
    "        return self.transformer.decoder(\n",
    "            self.positional_encoding(self.tgt_tok_emb(tgt)), memory, tgt_mask\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                                                 Param #\n",
       "===============================================================================================\n",
       "Seq2SeqTransformer                                                     --\n",
       "├─TokenEmbedder: 1-1                                                   --\n",
       "│    └─Embedding: 2-1                                                  108,664\n",
       "├─TokenEmbedder: 1-2                                                   --\n",
       "│    └─Embedding: 2-2                                                  210,880\n",
       "├─PositionalEncoding: 1-3                                              --\n",
       "│    └─Dropout: 2-3                                                    --\n",
       "├─Transformer: 1-4                                                     --\n",
       "│    └─TransformerEncoder: 2-4                                         --\n",
       "│    │    └─ModuleList: 3-1                                            54,192\n",
       "│    │    └─LayerNorm: 3-2                                             16\n",
       "│    └─TransformerDecoder: 2-5                                         --\n",
       "│    │    └─ModuleList: 3-3                                            56,016\n",
       "│    │    └─LayerNorm: 3-4                                             16\n",
       "├─Linear: 1-5                                                          237,240\n",
       "===============================================================================================\n",
       "Total params: 667,024\n",
       "Trainable params: 667,024\n",
       "Non-trainable params: 0\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = Seq2SeqTransformer(\n",
    "    num_encoder_layers=6,\n",
    "    num_decoder_layers=6,\n",
    "    emb_size=8,\n",
    "    max_len=128,\n",
    "    nhead=8,\n",
    "    src_vocab_size=len(vocab_transform[SRC_LANGUAGE]),\n",
    "    tgt_vocab_size=len(vocab_transform[TGT_LANGUAGE]),\n",
    "    dim_feedforward=512,\n",
    ").to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "summary(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(source, target): \n",
      "['In the beginning God created the heaven and the earth.'\n",
      " 'Au commencement, Dieu créa les cieux et la terre.']\n",
      "source_batch: torch.Size([63, 128])\n",
      "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
      "        [ 292,   10,   10,  ...,   10,   10,   10],\n",
      "        [   5,    5,   37,  ...,   31, 3261, 3261],\n",
      "        ...,\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1]])\n",
      "target_batch: torch.Size([65, 128])\n",
      "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
      "        [ 311,  108,   32,  ...,  287, 3698, 3698],\n",
      "        [1035,   95,   37,  ...,   10,    4,    4],\n",
      "        ...,\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1]])\n"
     ]
    }
   ],
   "source": [
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "\n",
    "    return func\n",
    "\n",
    "\n",
    "def input_transform(token_ids):\n",
    "    return torch.cat(\n",
    "        (torch.tensor([BOS_IDX]), torch.tensor(token_ids), torch.tensor([EOS_IDX])),\n",
    "    )\n",
    "\n",
    "\n",
    "def collator(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch\n",
    "\n",
    "\n",
    "text_transform = {}\n",
    "for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    text_transform[language] = sequential_transforms(\n",
    "        token_transform[language], vocab_transform[language], input_transform\n",
    "    )\n",
    "\n",
    "data_iter = langDF.values\n",
    "dataloader = DataLoader(data_iter, batch_size=BATCH_SIZE, collate_fn=collator)\n",
    "source_tensor, target_tensor = next(iter(dataloader))\n",
    "\n",
    "print(\"(source, target): \")\n",
    "print(next(iter(data_iter)))\n",
    "\n",
    "print(\"source_batch:\", source_tensor.shape)\n",
    "print(source_tensor)\n",
    "\n",
    "print(\"target_batch:\", target_tensor.shape)\n",
    "print(target_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_mask: torch.Size([63, 63])\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "target_mask: torch.Size([64, 64])\n",
      "tensor([[0., -inf, -inf,  ..., -inf, -inf, -inf],\n",
      "        [0., 0., -inf,  ..., -inf, -inf, -inf],\n",
      "        [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., -inf, -inf],\n",
      "        [0., 0., 0.,  ..., 0., 0., -inf],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "src_padding_mask: torch.Size([128, 63])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True]])\n",
      "tgt_padding_mask: torch.Size([128, 64])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True]])\n"
     ]
    }
   ],
   "source": [
    "def generate_square_subsequnt_mask(s):\n",
    "    mask = (torch.triu(torch.ones((s, s), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = (\n",
    "        mask.float()\n",
    "        .masked_fill(mask == 0, float(\"-inf\"))\n",
    "        .masked_fill(mask == 1, float(0.0))\n",
    "    )\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=DEVICE).type(torch.float)\n",
    "    tgt_mask = generate_square_subsequnt_mask(tgt_seq_len)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1).to(DEVICE)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1).to(DEVICE)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
    "\n",
    "\n",
    "target_input = target_tensor[:-1, :]\n",
    "target_out = target_tensor[1:, :]\n",
    "\n",
    "source_mask, target_mask, src_padding_mask, tgt_padding_mask = create_mask(\n",
    "    source_tensor, target_input\n",
    ")\n",
    "\n",
    "print(\"source_mask:\", source_mask.shape)\n",
    "print(source_mask)\n",
    "print(\"target_mask:\", target_mask.shape)\n",
    "print(target_mask)\n",
    "print(\"src_padding_mask:\", src_padding_mask.shape)\n",
    "print(src_padding_mask)\n",
    "print(\"tgt_padding_mask:\", tgt_padding_mask.shape)\n",
    "print(tgt_padding_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def run(epochs, epoch, model, optimizer, criterion, is_train, use_pbar=True):\n",
    "    model.train() if is_train else model.eval()\n",
    "    data_iter = langDF.values\n",
    "    dataloader = DataLoader(data_iter, batch_size=BATCH_SIZE, collate_fn=collator)\n",
    "    pbar = tqdm(dataloader, total=len(list(dataloader))) if use_pbar else dataloader\n",
    "    losses = 0\n",
    "    for source_batch, target_batch in pbar:\n",
    "        source_batch = source_batch.to(DEVICE)\n",
    "        target_batch = target_batch.to(DEVICE)\n",
    "\n",
    "        target_input = target_batch[:-1, :]\n",
    "        target_output = target_batch[1:, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(\n",
    "            source_batch, target_input\n",
    "        )\n",
    "\n",
    "        logits = model(\n",
    "            src=source_batch,\n",
    "            trg=target_input,\n",
    "            src_mask=src_mask,\n",
    "            tgt_mask=tgt_mask,\n",
    "            src_padding_mask=src_padding_mask,\n",
    "            tgt_padding_mask=tgt_padding_mask,\n",
    "            memory_key_padding_mask=src_padding_mask,\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(\n",
    "            logits.reshape(-1, logits.shape[-1]), target_output.reshape(-1)\n",
    "        )\n",
    "        if is_train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if use_pbar:\n",
    "                pbar.set_description(\n",
    "                    f\"Epoch: {epoch}/{epochs} | Loss: {loss.item():.6f}\"\n",
    "                )\n",
    "        losses += loss.item()\n",
    "    return losses / len(list(dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/243 [00:00<?, ?it/s]c:\\Users\\KDP-25\\.conda\\envs\\Torch_NLP38\\lib\\site-packages\\torch\\nn\\functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Epoch: 1/5 | Loss: 6.843336: 100%|██████████| 243/243 [17:21<00:00,  4.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 8.567610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/5 | Loss: 6.298216: 100%|██████████| 243/243 [17:38<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 6.569177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3/5 | Loss: 6.190910: 100%|██████████| 243/243 [16:51<00:00,  4.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 6.357454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4/5 | Loss: 6.069524: 100%|██████████| 243/243 [16:59<00:00,  4.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 6.241412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5/5 | Loss: 6.090706:  28%|██▊       | 68/243 [05:29<15:28,  5.31s/it]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "pre_loss = 100\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    loss = run(EPOCHS, epoch, model, optimizer, criterion, is_train=True)\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss:.6f}\")\n",
    "    if pre_loss > loss:\n",
    "        torch.save(model, f\"bible_transformer.pth\")\n",
    "        torch.save(model.state_dict(), f\"bible_transformer_state.pth\")\n",
    "        print(f\"Model Saved! --- Epoch: {epoch}, Loss: {loss:.6f}\")\n",
    "        pre_loss = loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_NLP38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
